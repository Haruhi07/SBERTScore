{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils import choose_best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dataset', 'origin', 'id', 'doc', 'summary', 'model_name', 'label',\n",
      "       'cut', 'DAE_score', 'DAE_label', 'QuestEval_score', 'QuestEval_label',\n",
      "       'SummaC-ZS_score', 'SummaC-ZS_label', 'SummaC-Conv_score',\n",
      "       'SummaC-Conv_label', 'QAFactEval_score', 'QAFactEval_label',\n",
      "       'sbert_score', 'combine_pos_score', 'bert_score', 'sbert_label',\n",
      "       'bert_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "excel_file = pd.read_excel(\"data/AggreFact-Unified-test.xlsx\", sheet_name=None)\n",
    "origin_names = ['cnn', 'xsum']\n",
    "sheet_names = ['in_pred', 'in_np', 'ex_pred', 'ex_np']\n",
    "xsum_sheet_names= ['in_sent', 'ex_sent']\n",
    "\n",
    "\n",
    "from utils import choose_best_threshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "score_df = pd.read_csv(\"data/aggre_fact_final_main-100.csv\")\n",
    "score_df = score_df.drop(labels=['Unnamed: 0'], axis=1)\n",
    "#score_df.to_csv(\"data/aggre_fact_final_main-100.csv\")\n",
    "\n",
    "dataset_list = ['XSumFaith', 'Polytope', 'FactCC', 'SummEval', 'FRANK', 'Wang20', 'CLIFF', 'Cao22', 'Goyal21']\n",
    "systems = ['DAE', 'QuestEval', 'SummaC-ZS', 'SummaC-Conv', 'QAFactEval', \n",
    "           'sbert', 'bert'\n",
    "           ]\n",
    "origins = ['cnndm', 'xsum']\n",
    "origin_mapping = {0: \"cnndm\", 1: \"xsum\", 2: \"overall\"}\n",
    "\n",
    "for system in systems:\n",
    "    score_df[f'{system}_label'] = None\n",
    "print(score_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Type Analysis on All data\n",
    "\n",
    "score_val = score_df[(score_df.cut == 'val') & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "\n",
    "for system in systems:\n",
    "    #for origin in origins:\n",
    "        #for dataset in dataset_list:\n",
    "        #    df_val_temp = score_val[(score_val.origin == origin) & (score_val.dataset == dataset)]\n",
    "        #    df_test_temp = score_test[(score_test.origin == origin) & (score_test.dataset == dataset)]\n",
    "    df_val_temp = score_val[]\n",
    "    df_test_temp = score_test[]\n",
    "\n",
    "    if len(df_val_temp) > 0 and len(df_test_temp) > 0:\n",
    "        best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "        scores_test = df_test_temp[f'{system}_score'].values\n",
    "        preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "        \n",
    "        score_df.loc[df_test_temp.index, f'{system}_label'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "sheet_name = ['in_pred', 'in_np', 'ex_pred', 'ex_np']\n",
    "for sheet_name in sheet_names:\n",
    "    origin_sheet_name = f'cnn_{sheet_name}'\n",
    "    \n",
    "    excel_file[origin_sheet_name].rename(columns={'summ': 'summary'}, inplace=True)\n",
    "    excel_file[origin_sheet_name]['id'] = excel_file[origin_sheet_name]['id'].astype(str)\n",
    "\n",
    "    df = excel_file[origin_sheet_name]\n",
    "    df.rename(columns={'label': f'{sheet_name}_label'}, inplace=True)\n",
    "    df['dataset'] = df['dataset'].str.lower()\n",
    "    score_df['dataset'] = score_df['dataset'].str.lower()\n",
    "    temp_score_df = score_df[score_df.origin == 'cnndm']\n",
    "    \n",
    "    result_df = pd.merge(temp_score_df, df, how='outer', on=['id', 'cut', 'summary', 'dataset', 'model_name'])\n",
    "    result_df[f'{sheet_name}_label'].fillna(1, inplace=True)\n",
    "    recalls = []\n",
    "    for system in systems:\n",
    "        test_df = result_df[result_df.cut=='test'].dropna()\n",
    "        recall = recall_score(test_df[f'{sheet_name}_label'].astype(int).tolist(), test_df[f\"{system}_label\"].tolist(), pos_label=0)\n",
    "        recalls.append(recall)\n",
    "    results_dict[sheet_name] = recalls\n",
    "\n",
    "recall_table = pd.DataFrame(\n",
    "    results_dict,\n",
    "    columns=sheet_names,\n",
    "    index=systems\n",
    ")\n",
    "display(recall_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Table 5!! Use the unified data\n",
    "\n",
    "score_val = score_df[(score_df.cut == 'val') & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "\n",
    "for system in systems:\n",
    "    for origin in origins:\n",
    "        #for dataset in dataset_list:\n",
    "        #    df_val_temp = score_val[(score_val.origin == origin) & (score_val.dataset == dataset)]\n",
    "        #    df_test_temp = score_test[(score_test.origin == origin) & (score_test.dataset == dataset)]\n",
    "        df_val_temp = score_val[(score_val.origin == origin)]\n",
    "        df_test_temp = score_test[(score_test.origin == origin)]\n",
    "\n",
    "        if len(df_val_temp) > 0 and len(df_test_temp) > 0:\n",
    "            best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "            scores_test = df_test_temp[f'{system}_score'].values\n",
    "            preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "            \n",
    "            score_df.loc[df_test_temp.index, f'{system}_label'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_pred</th>\n",
       "      <th>in_np</th>\n",
       "      <th>ex_pred</th>\n",
       "      <th>ex_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAE</th>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.686364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestEval</th>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.695455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.845455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAFactEval</th>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.522989</td>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.809091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              in_pred     in_np   ex_pred     ex_np\n",
       "DAE          0.563636  0.603448  0.632812  0.686364\n",
       "QuestEval    0.563636  0.609195  0.609375  0.690909\n",
       "SummaC-ZS    0.545455  0.545977  0.609375  0.695455\n",
       "SummaC-Conv  0.781818  0.689655  0.710938  0.845455\n",
       "QAFactEval   0.509091  0.522989  0.617188  0.772727\n",
       "sbert        0.800000  0.741379  0.875000  0.900000\n",
       "bert         0.690909  0.718391  0.812500  0.809091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_pred</th>\n",
       "      <th>in_np</th>\n",
       "      <th>in_sent</th>\n",
       "      <th>ex_pred</th>\n",
       "      <th>ex_np</th>\n",
       "      <th>ex_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAE</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>0.953191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestEval</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.639442</td>\n",
       "      <td>0.919149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.935323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940367</td>\n",
       "      <td>0.946215</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <td>0.464</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.444954</td>\n",
       "      <td>0.446215</td>\n",
       "      <td>0.617021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAFactEval</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.766055</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.876596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>0.608</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.573394</td>\n",
       "      <td>0.482072</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.794821</td>\n",
       "      <td>0.889362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             in_pred     in_np   in_sent   ex_pred     ex_np   ex_sent\n",
       "DAE            0.552  0.572139  0.923077  0.793578  0.760956  0.953191\n",
       "QuestEval      0.648  0.641791  0.923077  0.761468  0.639442  0.919149\n",
       "SummaC-ZS      0.936  0.935323  1.000000  0.940367  0.946215  0.957447\n",
       "SummaC-Conv    0.464  0.358209  0.307692  0.444954  0.446215  0.617021\n",
       "QAFactEval     0.800  0.761194  0.923077  0.766055  0.649402  0.876596\n",
       "sbert          0.608  0.462687  0.692308  0.573394  0.482072  0.765957\n",
       "bert           0.800  0.771144  1.000000  0.834862  0.794821  0.889362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "sheet_name = ['in_pred', 'in_np', 'ex_pred', 'ex_np']\n",
    "results_dict = {}\n",
    "for sheet_name in sheet_names:\n",
    "    origin_sheet_name = f'cnn_{sheet_name}'\n",
    "    \n",
    "    excel_file[origin_sheet_name].rename(columns={'summ': 'summary'}, inplace=True)\n",
    "    excel_file[origin_sheet_name]['id'] = excel_file[origin_sheet_name]['id'].astype(str)\n",
    "\n",
    "    df = excel_file[origin_sheet_name]\n",
    "    df.rename(columns={'label': f'{sheet_name}_label'}, inplace=True)\n",
    "    df['dataset'] = df['dataset'].str.lower()\n",
    "    score_df['dataset'] = score_df['dataset'].str.lower()\n",
    "    temp_score_df = score_df[score_df.origin == 'cnndm']\n",
    "    \n",
    "    result_df = pd.merge(temp_score_df, df, how='outer', on=['id', 'cut', 'summary', 'dataset', 'model_name'])\n",
    "    result_df[f'{sheet_name}_label'].fillna(1, inplace=True)\n",
    "    recalls = []\n",
    "    for system in systems:\n",
    "        test_df = result_df[result_df.cut=='test'].dropna()\n",
    "        recall = recall_score(test_df[f'{sheet_name}_label'].astype(int).tolist(), test_df[f\"{system}_label\"].tolist(), pos_label=0)\n",
    "        recalls.append(recall)\n",
    "    results_dict[sheet_name] = recalls\n",
    "\n",
    "recall_table = pd.DataFrame(\n",
    "    results_dict,\n",
    "    columns=sheet_names,\n",
    "    index=systems\n",
    ")\n",
    "display(recall_table)    \n",
    "\n",
    "xsum_sheet_names = ['in_pred', 'in_np', 'in_sent', 'ex_pred', 'ex_np', 'ex_sent']\n",
    "results_dict = {}\n",
    "for sheet_name in xsum_sheet_names:\n",
    "    origin_sheet_name = f'xsum_{sheet_name}'\n",
    "\n",
    "    excel_file[origin_sheet_name].rename(columns={'summ': 'summary'}, inplace=True)\n",
    "    excel_file[origin_sheet_name]['id'] = excel_file[origin_sheet_name]['id'].astype(str)\n",
    "\n",
    "    df = excel_file[origin_sheet_name]\n",
    "    df.rename(columns={'label': f'{sheet_name}_label'}, inplace=True)\n",
    "    df['dataset'] = df['dataset'].str.lower()\n",
    "    score_df['dataset'] = score_df['dataset'].str.lower()\n",
    "    df[\"origin\"].fillna(\"xsum\", inplace=True)\n",
    "    df[\"dataset\"].replace(\"goyaldurrett2021\", \"goyal21\", inplace=True)\n",
    "    temp_score_df = score_df[score_df.origin == 'xsum']\n",
    "\n",
    "    result_df = pd.merge(temp_score_df, df, how='outer', on=['id', 'summary', 'dataset', 'cut', 'model_name'])\n",
    "    result_df[f'{sheet_name}_label'].fillna(1, inplace=True)\n",
    "    recalls = []\n",
    "    for system in systems:\n",
    "        test_df = result_df[result_df.cut=='test'].dropna()\n",
    "        recall = recall_score(test_df[f'{sheet_name}_label'].tolist(), test_df[f\"{system}_label\"].tolist(), pos_label=0)\n",
    "        recalls.append(recall)\n",
    "    results_dict[sheet_name] = recalls\n",
    "        \n",
    "\n",
    "recall_table = pd.DataFrame(\n",
    "    results_dict,\n",
    "    columns=xsum_sheet_names,\n",
    "    index=systems\n",
    ")\n",
    "display(recall_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Threshold\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>in_pred</th>\n",
    "      <th>in_np</th>\n",
    "      <th>ex_pred</th>\n",
    "      <th>ex_np</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.563636</td>\n",
    "      <td>0.603448</td>\n",
    "      <td>0.632812</td>\n",
    "      <td>0.686364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.563636</td>\n",
    "      <td>0.609195</td>\n",
    "      <td>0.609375</td>\n",
    "      <td>0.690909</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.545455</td>\n",
    "      <td>0.545977</td>\n",
    "      <td>0.609375</td>\n",
    "      <td>0.695455</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.781818</td>\n",
    "      <td>0.689655</td>\n",
    "      <td>0.710938</td>\n",
    "      <td>0.845455</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.509091</td>\n",
    "      <td>0.522989</td>\n",
    "      <td>0.617188</td>\n",
    "      <td>0.772727</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.800000</td>\n",
    "      <td>0.741379</td>\n",
    "      <td>0.875000</td>\n",
    "      <td>0.900000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.690909</td>\n",
    "      <td>0.718391</td>\n",
    "      <td>0.812500</td>\n",
    "      <td>0.809091</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>in_pred</th>\n",
    "      <th>in_np</th>\n",
    "      <th>in_sent</th>\n",
    "      <th>ex_pred</th>\n",
    "      <th>ex_np</th>\n",
    "      <th>ex_sent</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.552</td>\n",
    "      <td>0.572139</td>\n",
    "      <td>0.923077</td>\n",
    "      <td>0.793578</td>\n",
    "      <td>0.760956</td>\n",
    "      <td>0.953191</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.648</td>\n",
    "      <td>0.641791</td>\n",
    "      <td>0.923077</td>\n",
    "      <td>0.761468</td>\n",
    "      <td>0.639442</td>\n",
    "      <td>0.919149</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.936</td>\n",
    "      <td>0.935323</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.940367</td>\n",
    "      <td>0.946215</td>\n",
    "      <td>0.957447</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.464</td>\n",
    "      <td>0.358209</td>\n",
    "      <td>0.307692</td>\n",
    "      <td>0.444954</td>\n",
    "      <td>0.446215</td>\n",
    "      <td>0.617021</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.800</td>\n",
    "      <td>0.761194</td>\n",
    "      <td>0.923077</td>\n",
    "      <td>0.766055</td>\n",
    "      <td>0.649402</td>\n",
    "      <td>0.876596</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.608</td>\n",
    "      <td>0.462687</td>\n",
    "      <td>0.692308</td>\n",
    "      <td>0.573394</td>\n",
    "      <td>0.482072</td>\n",
    "      <td>0.765957</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.800</td>\n",
    "      <td>0.771144</td>\n",
    "      <td>1.000000</td>\n",
    "      <td>0.834862</td>\n",
    "      <td>0.794821</td>\n",
    "      <td>0.889362</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>cnndm</th>\n",
    "      <th>xsum</th>\n",
    "      <th>all</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.784862</td>\n",
    "      <td>0.757256</td>\n",
    "      <td>0.873665</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.727684</td>\n",
    "      <td>0.654354</td>\n",
    "      <td>0.874377</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.700946</td>\n",
    "      <td>0.218997</td>\n",
    "      <td>0.842705</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.693130</td>\n",
    "      <td>0.720317</td>\n",
    "      <td>0.750178</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.862608</td>\n",
    "      <td>0.722955</td>\n",
    "      <td>0.874733</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.665981</td>\n",
    "      <td>0.675462</td>\n",
    "      <td>0.752669</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.768819</td>\n",
    "      <td>0.686016</td>\n",
    "      <td>0.761922</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple threshold\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>in_pred</th>\n",
    "      <th>in_np</th>\n",
    "      <th>ex_pred</th>\n",
    "      <th>ex_np</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.509091</td>\n",
    "      <td>0.574713</td>\n",
    "      <td>0.609375</td>\n",
    "      <td>0.668182</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.581818</td>\n",
    "      <td>0.695402</td>\n",
    "      <td>0.742188</td>\n",
    "      <td>0.777273</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.745455</td>\n",
    "      <td>0.632184</td>\n",
    "      <td>0.710938</td>\n",
    "      <td>0.800000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.781818</td>\n",
    "      <td>0.683908</td>\n",
    "      <td>0.710938</td>\n",
    "      <td>0.840909</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.509091</td>\n",
    "      <td>0.545977</td>\n",
    "      <td>0.632812</td>\n",
    "      <td>0.790909</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.436364</td>\n",
    "      <td>0.454023</td>\n",
    "      <td>0.562500</td>\n",
    "      <td>0.586364</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.636364</td>\n",
    "      <td>0.660920</td>\n",
    "      <td>0.718750</td>\n",
    "      <td>0.740909</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>in_pred</th>\n",
    "      <th>in_np</th>\n",
    "      <th>in_sent</th>\n",
    "      <th>ex_pred</th>\n",
    "      <th>ex_np</th>\n",
    "      <th>ex_sent</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.584</td>\n",
    "      <td>0.606965</td>\n",
    "      <td>0.923077</td>\n",
    "      <td>0.834862</td>\n",
    "      <td>0.796813</td>\n",
    "      <td>0.961702</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.528</td>\n",
    "      <td>0.487562</td>\n",
    "      <td>0.923077</td>\n",
    "      <td>0.637615</td>\n",
    "      <td>0.500000</td>\n",
    "      <td>0.855319</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.640</td>\n",
    "      <td>0.656716</td>\n",
    "      <td>0.769231</td>\n",
    "      <td>0.564220</td>\n",
    "      <td>0.517928</td>\n",
    "      <td>0.514894</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.648</td>\n",
    "      <td>0.567164</td>\n",
    "      <td>0.384615</td>\n",
    "      <td>0.614679</td>\n",
    "      <td>0.635458</td>\n",
    "      <td>0.710638</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.720</td>\n",
    "      <td>0.686567</td>\n",
    "      <td>0.846154</td>\n",
    "      <td>0.646789</td>\n",
    "      <td>0.539841</td>\n",
    "      <td>0.804255</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.664</td>\n",
    "      <td>0.532338</td>\n",
    "      <td>0.769231</td>\n",
    "      <td>0.678899</td>\n",
    "      <td>0.567729</td>\n",
    "      <td>0.817021</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.632</td>\n",
    "      <td>0.557214</td>\n",
    "      <td>0.846154</td>\n",
    "      <td>0.651376</td>\n",
    "      <td>0.613546</td>\n",
    "      <td>0.778723</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>cnndm</th>\n",
    "      <th>xsum</th>\n",
    "      <th>all</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>DAE</th>\n",
    "      <td>0.859317</td>\n",
    "      <td>0.749340</td>\n",
    "      <td>0.844484</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QuestEval</th>\n",
    "      <td>0.697244</td>\n",
    "      <td>0.525066</td>\n",
    "      <td>0.674021</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-ZS</th>\n",
    "      <td>0.774167</td>\n",
    "      <td>0.617414</td>\n",
    "      <td>0.753025</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>SummaC-Conv</th>\n",
    "      <td>0.738791</td>\n",
    "      <td>0.643799</td>\n",
    "      <td>0.725979</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>QAFactEval</th>\n",
    "      <td>0.878239</td>\n",
    "      <td>0.649077</td>\n",
    "      <td>0.847331</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>sbert</th>\n",
    "      <td>0.785274</td>\n",
    "      <td>0.715040</td>\n",
    "      <td>0.775801</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>bert</th>\n",
    "      <td>0.732620</td>\n",
    "      <td>0.480211</td>\n",
    "      <td>0.698577</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_val = score_df[(score_df.cut == 'val') & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "\n",
    "for system in systems:\n",
    "    for origin in origins:\n",
    "    #    for dataset in dataset_list:\n",
    "    #        df_val_temp = score_val[(score_val.origin == origin) & (score_val.dataset == dataset)]\n",
    "    #        df_test_temp = score_test[(score_test.origin == origin) & (score_test.dataset == dataset)]\n",
    "        df_val_temp = score_val[(score_val.origin == origin)]\n",
    "        df_test_temp = score_test[(score_test.origin == origin)]\n",
    "\n",
    "        if len(df_val_temp) > 0 and len(df_test_temp) > 0:\n",
    "            best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "            scores_test = df_test_temp[f'{system}_score'].values\n",
    "            preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "            \n",
    "            score_df.loc[df_test_temp.index, f'{system}_label'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnndm</th>\n",
       "      <th>xsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAE</th>\n",
       "      <td>0.784862</td>\n",
       "      <td>0.757256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestEval</th>\n",
       "      <td>0.727684</td>\n",
       "      <td>0.654354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <td>0.700946</td>\n",
       "      <td>0.218997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.720317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAFactEval</th>\n",
       "      <td>0.862608</td>\n",
       "      <td>0.722955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>0.665981</td>\n",
       "      <td>0.675462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.768819</td>\n",
       "      <td>0.686016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cnndm      xsum\n",
       "DAE          0.784862  0.757256\n",
       "QuestEval    0.727684  0.654354\n",
       "SummaC-ZS    0.700946  0.218997\n",
       "SummaC-Conv  0.693130  0.720317\n",
       "QAFactEval   0.862608  0.722955\n",
       "sbert        0.665981  0.675462\n",
       "bert         0.768819  0.686016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recall of correct summaries\n",
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'goyal21'))]\n",
    "cnn_score_test_pos = score_test[(score_test.origin == 'cnndm')]\n",
    "xsum_score_test_pos = score_test[(score_test.origin == 'xsum')]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "recalls = []\n",
    "for system in systems:\n",
    "    system_labels = cnn_score_test_pos[f'{system}_label'].values.tolist()\n",
    "    labels = cnn_score_test_pos['label'].values.tolist()\n",
    "    recall = recall_score(labels, system_labels)\n",
    "    recalls.append(recall)\n",
    "\n",
    "results_dict['cnndm'] = recalls\n",
    "\n",
    "recalls = []\n",
    "for system in systems:\n",
    "    system_labels = xsum_score_test_pos[f'{system}_label'].values.tolist()\n",
    "    labels = xsum_score_test_pos['label'].values.tolist()\n",
    "    recall = recall_score(labels, system_labels)\n",
    "    recalls.append(recall)\n",
    "\n",
    "results_dict['xsum'] = recalls\n",
    "    \n",
    "recall_table = pd.DataFrame(\n",
    "    results_dict,\n",
    "    columns=[\"cnndm\", \"xsum\"],\n",
    "    index=systems\n",
    ")\n",
    "display(recall_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Table 5!! Use the unified data\n",
    "\n",
    "score_val = score_df[(score_df.cut == 'val') & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'Goyal21'))]\n",
    "\n",
    "for system in systems:\n",
    "    #for origin in origins:\n",
    "    #    for dataset in dataset_list:\n",
    "    #        df_val_temp = score_val[(score_val.origin == origin) & (score_val.dataset == dataset)]\n",
    "    #        df_test_temp = score_test[(score_test.origin == origin) & (score_test.dataset == dataset)]\n",
    "    df_val_temp = score_val\n",
    "    df_test_temp = score_test\n",
    "\n",
    "    if len(df_val_temp) > 0 and len(df_test_temp) > 0:\n",
    "        best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "        scores_test = df_test_temp[f'{system}_score'].values\n",
    "        preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "        \n",
    "        score_df.loc[df_test_temp.index, f'{system}_label'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnndm</th>\n",
       "      <th>xsum</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAE</th>\n",
       "      <td>0.784862</td>\n",
       "      <td>0.757256</td>\n",
       "      <td>0.873665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuestEval</th>\n",
       "      <td>0.727684</td>\n",
       "      <td>0.654354</td>\n",
       "      <td>0.874377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <td>0.700946</td>\n",
       "      <td>0.218997</td>\n",
       "      <td>0.842705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.720317</td>\n",
       "      <td>0.750178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAFactEval</th>\n",
       "      <td>0.862608</td>\n",
       "      <td>0.722955</td>\n",
       "      <td>0.874733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>0.665981</td>\n",
       "      <td>0.675462</td>\n",
       "      <td>0.752669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>0.768819</td>\n",
       "      <td>0.686016</td>\n",
       "      <td>0.761922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cnndm      xsum       all\n",
       "DAE          0.784862  0.757256  0.873665\n",
       "QuestEval    0.727684  0.654354  0.874377\n",
       "SummaC-ZS    0.700946  0.218997  0.842705\n",
       "SummaC-Conv  0.693130  0.720317  0.750178\n",
       "QAFactEval   0.862608  0.722955  0.874733\n",
       "sbert        0.665981  0.675462  0.752669\n",
       "bert         0.768819  0.686016  0.761922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_test = score_df[(score_df.cut == 'test')  & ((score_df.origin != 'cnndm') | (score_df.dataset != 'goyal21'))]\n",
    "score_test_pos = score_test\n",
    "\n",
    "recalls = []\n",
    "for system in systems:\n",
    "    system_labels = score_test_pos[f'{system}_label'].values.tolist()\n",
    "    labels = score_test_pos['label'].values.tolist()\n",
    "    recall = recall_score(labels, system_labels)\n",
    "    recalls.append(recall)\n",
    "\n",
    "results_dict['all'] = recalls\n",
    "\n",
    "recall_table = pd.DataFrame(\n",
    "    results_dict,\n",
    "    columns=[\"cnndm\", \"xsum\", 'all'],\n",
    "    index=systems\n",
    ")\n",
    "display(recall_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
